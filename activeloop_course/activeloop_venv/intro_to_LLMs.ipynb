{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # this will load variables from .env\n",
    "\n",
    "# Now you can access the variables\n",
    "ACTIVELOOP_TOKEN = os.getenv('ACTIVELOOP_TOKEN')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "GOOGLE_CSE_ID = os.getenv('GOOGLE_CSE_ID')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Rainbow Socks Co.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "\n",
    "print(llm(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 48\n",
      "\tPrompt Tokens: 4\n",
      "\tCompletion Tokens: 44\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00096\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", n=2, best_of=2)\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm(\"Tell me a joke\")\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# create our examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What's the weather like?\",\n",
    "        \"answer\": \"It's raining cats and dogs, better bring an umbrella!\"\n",
    "    }, {\n",
    "        \"query\": \"How old are you?\",\n",
    "        \"answer\": \"Age is just a number, but I'm timeless.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# create an example template\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
    "assistant. The assistant is known for its humor and wit, providing\n",
    "entertaining and amusing responses to users' questions. Here are some\n",
    "examples:\n",
    "\"\"\"\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "# now create the few-shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Life is about finding joy and contentment in whatever you do, and living each day to the fullest!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n",
    "chain.run(\"What's the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(\n",
    "        template=template,\n",
    "    input_variables=['question']\n",
    ")\n",
    "\n",
    "# user question\n",
    "question = \"What is the capital city of France?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dannyhughes/Documents/activeloop_course/activeloop_venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain\n",
    "\n",
    "# initialize Hub LLM\n",
    "hub_llm = HuggingFaceHub(\n",
    "        repo_id='google/flan-t5-large',\n",
    "    model_kwargs={'temperature':0}\n",
    ")\n",
    "\n",
    "# create prompt template > LLM chain\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=hub_llm\n",
    ")\n",
    "\n",
    "# ask the user question about the capital of France\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = [\n",
    "    {'question': \"What is the capital city of France?\"},\n",
    "    {'question': \"What is the largest mammal on Earth?\"},\n",
    "    {'question': \"Which gas is most abundant in Earth's atmosphere?\"},\n",
    "    {'question': \"What color is a ripe banana?\"}\n",
    "]\n",
    "res = llm_chain.generate(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris\\nBlue Whale\\nNitrogen\\nYellow'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_template = \"\"\"Answer the following questions one at a time.\n",
    "\n",
    "Questions:\n",
    "{questions}\n",
    "\n",
    "Answers:\n",
    "\"\"\"\n",
    "long_prompt = PromptTemplate(template=multi_template, input_variables=[\"questions\"])\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    prompt=long_prompt,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "qs_str = (\n",
    "    \"What is the capital city of France?\\n\" +\n",
    "    \"What is the largest mammal on Earth?\\n\" +\n",
    "    \"Which gas is most abundant in Earth's atmosphere?\\n\" +\n",
    "\t\t\"What color is a ripe banana?\\n\"\n",
    ")\n",
    "llm_chain.run(qs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dannyhughes/Documents/activeloop_course/activeloop_venv/lib/python3.9/site-packages/langchain/llms/openai.py:179: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/dannyhughes/Documents/activeloop_course/activeloop_venv/lib/python3.9/site-packages/langchain/llms/openai.py:748: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_template = \"Summarize the following text to one sentence: {text}\"\n",
    "summarization_prompt = PromptTemplate(input_variables=[\"text\"], template=summarization_template)\n",
    "summarization_chain = LLMChain(llm=llm, prompt=summarization_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain offers various modules for building language model applications, which can be used individually or combined to create complex applications, with the most basic building block being calling an LLM on input, as demonstrated in a simple example of building a company name generator.\n"
     ]
    }
   ],
   "source": [
    "text = \"LangChain provides many modules that can be used to build language model applications. Modules can be combined to create more complex applications, or be used individually for simple applications. The most basic building block of LangChain is calling an LLM on some input. Let’s walk through a simple example of how to do this. For this purpose, let’s pretend we are building a service that generates a company name based on what the company makes.\"\n",
    "summarized_text = summarization_chain.predict(text=text)\n",
    "print(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_template = \"Translate the following text from {source_language} to {target_language}: {text}\"\n",
    "translation_prompt = PromptTemplate(input_variables=[\"source_language\", \"target_language\", \"text\"], template=translation_template)\n",
    "translation_chain = LLMChain(llm=llm, prompt=translation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Votre texte ici\n"
     ]
    }
   ],
   "source": [
    "source_language = \"English\"\n",
    "target_language = \"French\"\n",
    "text = \"Your text here\"\n",
    "translated_text = translation_chain.predict(source_language=source_language, target_language=target_language, text=text)\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_urls_from_xml_file(file_path):\n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        tree = ET.parse(file_path)\n",
    "\n",
    "        # Get the root of the XML document\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Define the namespace\n",
    "        ns = {'sitemap': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "\n",
    "        # Extract URLs\n",
    "        urls = [element.text for element in root.findall('sitemap:loc', ns)]\n",
    "\n",
    "        # Print the URLs\n",
    "        for url in urls:\n",
    "            print(url)\n",
    "    except ET.ParseError as e:\n",
    "        print(f'Parse error: {e}')\n",
    "\n",
    "# Specify the path to your XML file\n",
    "file_path = '/Users/dannyhughes/Documents/activeloop_course/activeloop_venv/dune_xml.txt'\n",
    "\n",
    "extract_urls_from_xml_file(file_path)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_urls_from_xml_file(file_path, output_file_path):\n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        tree = ET.parse(file_path)\n",
    "\n",
    "        # Get the root of the XML document\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Define the namespace\n",
    "        ns = {'sitemap': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "\n",
    "        # Extract URLs\n",
    "        urls = [element.text for element in root.findall('sitemap:url', ns)]\n",
    "        \n",
    "        # Create a new root for the output XML\n",
    "        new_root = ET.Element('urlset')\n",
    "        new_root.set('xmlns', 'http://www.sitemaps.org/schemas/sitemap/0.9')\n",
    "\n",
    "        # For each URL, create a new url element with a loc subelement\n",
    "        for url in urls:\n",
    "            url_element = ET.SubElement(new_root, 'url')\n",
    "            loc_element = ET.SubElement(url_element, 'loc')\n",
    "            loc_element.text = url\n",
    "\n",
    "        # Wrap the root element in an ElementTree and write it to the output file\n",
    "        new_tree = ET.ElementTree(new_root)\n",
    "        new_tree.write(output_file_path, encoding='utf-8', xml_declaration=True)\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f'Parse error: {e}')\n",
    "\n",
    "# Specify the path to your XML file and the output file\n",
    "file_path = '/Users/dannyhughes/Documents/activeloop_course/activeloop_venv/dune_xml.txt'\n",
    "output_file_path = '/Users/dannyhughes/Documents/activeloop_course/activeloop_venv/dune_xml.xml'\n",
    "\n",
    "extract_urls_from_xml_file(file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_urls_from_xml_file(file_path, output_file_path):\n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        tree = ET.parse(file_path)\n",
    "\n",
    "        # Get the root of the XML document\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Define the namespace\n",
    "        ns = {'sitemap': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "\n",
    "        # Extract URLs\n",
    "        urls = [element.text for element in root.findall('./sitemap:url/sitemap:loc', ns)]\n",
    "\n",
    "        # Create a new root for the output XML\n",
    "        new_root = ET.Element('urlset')\n",
    "        new_root.set('xmlns', 'http://www.sitemaps.org/schemas/sitemap/0.9')\n",
    "\n",
    "        # For each URL, create a new url element with a loc subelement\n",
    "        for url in urls:\n",
    "            url_element = ET.SubElement(new_root, 'url')\n",
    "            loc_element = ET.SubElement(url_element, 'loc')\n",
    "            loc_element.text = url\n",
    "\n",
    "        # Wrap the root element in an ElementTree and write it to the output file\n",
    "        new_tree = ET.ElementTree(new_root)\n",
    "        new_tree.write(output_file_path, encoding='utf-8', xml_declaration=True)\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f'Parse error: {e}')\n",
    "\n",
    "# Specify the path to your XML file and the output file\n",
    "file_path = '/Users/dannyhughes/Documents/activeloop_course/activeloop_venv/dune_xml.txt'\n",
    "output_file_path = '/Users/dannyhughes/Documents/activeloop_course/activeloop_venv/dune_xml.xml'\n",
    "\n",
    "extract_urls_from_xml_file(file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Set the local path to the cloned repository\n",
    "repo_path = \"/Users/dannyhughes/Documents/spellbook\"\n",
    "\n",
    "# Set the GitHub repository URL\n",
    "github_repo_url = \"https://github.com/duneanalytics/spellbook\"\n",
    "\n",
    "def add_files_to_sitemap(root, path):\n",
    "    # Create the full path to the current directory or file\n",
    "    full_path = os.path.join(repo_path, path)\n",
    "\n",
    "    if os.path.isdir(full_path):\n",
    "        # If it's a directory, iterate over its contents\n",
    "        for file_name in os.listdir(full_path):\n",
    "            # Call this function recursively for each file in the directory\n",
    "            add_files_to_sitemap(root, os.path.join(path, file_name))\n",
    "    else:\n",
    "        # This is a file, add its URL to the XML\n",
    "        # Construct the GitHub file URL based on the repository URL and the relative file path\n",
    "        file_url = f\"{github_repo_url}/blob/main/{path}\"\n",
    "\n",
    "        # Create a new \"url\" XML element\n",
    "        url_elem = ET.SubElement(root, \"url\")\n",
    "\n",
    "        # Create a \"loc\" element containing the file URL\n",
    "        loc_elem = ET.SubElement(url_elem, \"loc\")\n",
    "        loc_elem.text = file_url\n",
    "\n",
    "# Create a new XML root element\n",
    "root = ET.Element(\"urlset\", xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\")\n",
    "\n",
    "# Start the recursion with the root directory\n",
    "add_files_to_sitemap(root, \"models\")\n",
    "\n",
    "# Convert the XML to a string\n",
    "xml_str = ET.tostring(root, encoding=\"unicode\")\n",
    "\n",
    "# Save the XML to a file\n",
    "with open(\"github_sitemap.xml\", \"w\") as f:\n",
    "    f.write(xml_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activeloop_venv",
   "language": "python",
   "name": "activeloop_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
